{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from autofeat import AutoFeatClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the data, and delete unrelevant columns\n",
    "data = pd.read_csv(r'C:\\Users\\Ardon\\Documents\\Thesis\\processminer-sheet-break-rare-event-dataset.csv')\n",
    "data = data.drop(['DateTime','Grade&Bwt','EventPress'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to move Y back in time\n",
    "sign = lambda x: (1, -1)[x < 0]\n",
    "\n",
    "def shift_back(df, back):\n",
    "    vector = df['SheetBreak'].copy()\n",
    "    for s in range(abs(back)):\n",
    "        tmp = vector.shift(sign(back))\n",
    "        tmp = tmp.fillna(0)\n",
    "        vector += tmp\n",
    "    labelcol = 'SheetBreak'\n",
    "    df.insert(loc=0, column=labelcol+'tmp', value=vector)\n",
    "    df = df.drop(df[df[labelcol] == 1].index)\n",
    "    df = df.drop(labelcol, axis=1)\n",
    "    df = df.rename(columns={labelcol+'tmp': labelcol})\n",
    "    df.loc[df[labelcol] > 0, labelcol] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Move Y back two time steps\n",
    "data_time_back = shift_back(data, -2)\n",
    "## Reset the index\n",
    "data_time_back.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Divide the dataframe into X and y variables\n",
    "X = data_time_back.loc[:, data_time_back.columns != 'SheetBreak']\n",
    "y = data_time_back.loc[:, data_time_back.columns == 'SheetBreak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat] The 1 step feature engineering process could generate up to 413 features.\n",
      "[AutoFeat] With 16258 data points this new feature matrix would use about 0.03 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 267 transformed features from 59 original features - done.\n",
      "[feateng] Generated altogether 270 new features in 1 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n",
      "[feateng] Generated a total of 231 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/5\n",
      "[featsel] Feature selection run 2/5\n",
      "[featsel] Feature selection run 3/5\n",
      "[featsel] Feature selection run 4/5\n",
      "[featsel] Feature selection run 5/5\n",
      "[featsel] 118 features after 5 feature selection runs\n",
      "[featsel] 102 features after correlation filtering\n",
      "[featsel] 68 features after noise filtering\n",
      "[AutoFeat] Computing 45 new features.\n",
      "[AutoFeat]    45/   45 new features ...done.\n",
      "[AutoFeat] Final dataframe with 104 feature columns (45 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[-1.00543104e-07]\n",
      "0.000154 * CouchSpd**3\n",
      "0.000032 * x1PrsTopDrw**3\n",
      "0.000022 * x1PrsTopSpd**3\n",
      "0.000014 * BlndStckFloTPD**2\n",
      "[AutoFeat] Final score: 0.4328\n",
      "[AutoFeat] Computing 45 new features.\n",
      "[AutoFeat]    45/   45 new features ...done.\n",
      "autofeat new features: 45\n",
      "autofeat Acc. on training data: 0.43283306679788414\n",
      "autofeat Acc. on test data: 0.44059040590405907\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering and selection with 1 step, and 5 feature selection runs.\n",
    "set_seed = 123\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "# run autofeat\n",
    "afc = AutoFeatClassifier(verbose=1, feateng_steps=1)\n",
    "# fit autofeat on less data, otherwise ridge reg model with xval will overfit on new features\n",
    "X_train_tr = afc.fit_transform(X_train, y_train)\n",
    "X_test_tr = afc.transform(X_test)\n",
    "print(\"autofeat new features:\", len(afc.new_feat_cols_))\n",
    "print(\"autofeat Acc. on training data:\", accuracy_score(y_train, afc.predict(X_train_tr)))\n",
    "print(\"autofeat Acc. on test data:\", accuracy_score(y_test, afc.predict(X_test_tr)))\n",
    "X_1step_5runs_2 = afc.transform(X)\n",
    "data_1step_5runs_2 = pd.concat([y, X_1step_5runs_2], axis=1)\n",
    "data_1step_5runs_2.to_csv('data_1step_5runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AutoFeat] The 2 step feature engineering process could generate up to 85491 features.\n",
      "[AutoFeat] With 16258 data points this new feature matrix would use about 5.56 gb of space.\n",
      "[feateng] Step 1: transformation of original features\n",
      "[feateng] Generated 267 transformed features from 59 original features - done.\n",
      "[feateng] Step 2: first combination of features\n",
      "[feateng]           41500/          52975 feature tuples combined\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ardon\\Anaconda3\\envs\\thesis\\lib\\site-packages\\numpy\\core\\_methods.py:199: RuntimeWarning: overflow encountered in reduce\n",
      "  ret = umr_sum(x, axis, dtype, out, keepdims)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng]           50600/          52975 feature tuples combined\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ardon\\Anaconda3\\envs\\thesis\\lib\\site-packages\\numpy\\core\\_methods.py:195: RuntimeWarning: overflow encountered in multiply\n",
      "  x = um.multiply(x, x, out=x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng] Generated 52691 feature combinations from 52975 original feature tuples - done.\n",
      "[feateng] Generated altogether 53040 new features in 2 steps\n",
      "[feateng] Removing correlated features, as well as additions at the highest level\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ardon\\Anaconda3\\envs\\thesis\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1546: RuntimeWarning: overflow encountered in multiply\n",
      "  sqr = np.multiply(arr, arr, out=arr)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[feateng] Generated a total of 41023 additional features\n",
      "[featsel] Scaling data...done.\n",
      "[featsel] Feature selection run 1/1\n",
      "[featsel] 2 features after 1 feature selection runs\n",
      "[featsel] 2 features after correlation filtering\n",
      "[featsel] 2 features after noise filtering\n",
      "[AutoFeat] Computing 2 new features.\n",
      "[AutoFeat]     2/    2 new features ...done.\n",
      "[AutoFeat] Final dataframe with 61 feature columns (2 new).\n",
      "[AutoFeat] Training final classification model.\n",
      "[AutoFeat] Trained model: largest coefficients:\n",
      "[-0.01120464]\n",
      "0.031250 * exp(UpprHdTmpRL)/BleachedGWDFlow\n",
      "0.000295 * 1/(CT1BLADEPSI*RSBWSCANAVG)\n",
      "[AutoFeat] Final score: 0.9352\n",
      "[AutoFeat] Computing 2 new features.\n",
      "[AutoFeat]     2/    2 new features ...done.\n",
      "autofeat new features: 2\n",
      "autofeat Acc. on training data: 0.9352318858408168\n",
      "autofeat Acc. on test data: 0.9306273062730628\n",
      "[AutoFeat] Computing 2 new features.\n",
      "[AutoFeat]     2/    2 new features ...done.\n",
      "93567.92763996124\n"
     ]
    }
   ],
   "source": [
    "# Feature engineering and selection with 2 steps, and 1 feature selection run.\n",
    "start = time.time()\n",
    "set_seed = 12345\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "y_train = np.ravel(y_train)\n",
    "y_test = np.ravel(y_test)\n",
    "# run autofeat\n",
    "afc_2 = AutoFeatClassifier(verbose=1, feateng_steps=2, featsel_runs=1)\n",
    "# fit autofeat on less data, otherwise ridge reg model with xval will overfit on new features\n",
    "X_train_tr = afc_2.fit_transform(X_train, y_train)\n",
    "X_test_tr = afc_2.transform(X_test)\n",
    "print(\"autofeat new features:\", len(afc_2.new_feat_cols_))\n",
    "print(\"autofeat Acc. on training data:\", accuracy_score(y_train, afc_2.predict(X_train_tr)))\n",
    "print(\"autofeat Acc. on test data:\", accuracy_score(y_test, afc_2.predict(X_test_tr)))\n",
    "X_2steps_1run = afc_2.transform(X)\n",
    "data_2steps_1run = pd.concat([y, X_2steps_1run], axis=1)\n",
    "data_2steps_1run.to_csv('data_2steps_1run.csv')\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
