{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import all the required libraries and functions\n",
    "import pandas as pd\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from imblearn.ensemble import RUSBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import the data and split the data set into X and y variables\n",
    "data = pd.read_csv(r'C:\\Users\\Ardon\\Documents\\Thesis\\data_1step_5runs.csv')\n",
    "data = data.drop(['Unnamed: 0'], axis=1)\n",
    "X = data.loc[:, data.columns != 'SheetBreak']\n",
    "y = data.loc[:, data.columns == 'SheetBreak']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split the data into a training set and validation set \n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 92)\n",
    "\n",
    "## Ravel the y data. Ravel means turning a data frame into an array\n",
    "y_train = np.ravel(y_train)\n",
    "y_val = np.ravel(y_val)\n",
    "\n",
    "## Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.fit_transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3877  133]\n",
      " [  45   10]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      4010\n",
      "         1.0       0.07      0.18      0.10        55\n",
      "\n",
      "    accuracy                           0.96      4065\n",
      "   macro avg       0.53      0.57      0.54      4065\n",
      "weighted avg       0.98      0.96      0.97      4065\n",
      "\n",
      "1.0799987316131592\n"
     ]
    }
   ],
   "source": [
    "## RusBoost with a decision tree as base estimator \n",
    "start = time.time()\n",
    "clf_rus = RUSBoostClassifier(random_state = 166, base_estimator = DecisionTreeClassifier())\n",
    "\n",
    "found = clf_rus.fit(X_train, y_train)  \n",
    "predicted = found.predict(X_val)\n",
    "print(confusion_matrix(y_val, predicted))\n",
    "print(classification_report(y_val, predicted))\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3913   97]\n",
      " [  37   18]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      4010\n",
      "         1.0       0.16      0.33      0.21        55\n",
      "\n",
      "    accuracy                           0.97      4065\n",
      "   macro avg       0.57      0.65      0.60      4065\n",
      "weighted avg       0.98      0.97      0.97      4065\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## RusBoost with a random forest classifier as base estimator \n",
    "clf_rus = RUSBoostClassifier(random_state = 24, base_estimator = RandomForestClassifier())\n",
    "\n",
    "found = clf_rus.fit(X_train, y_train)  \n",
    "predicted = found.predict(X_val)\n",
    "print(confusion_matrix(y_val, predicted))\n",
    "print(classification_report(y_val, predicted))\n",
    "#print(found.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2839 1171]\n",
      " [  11   44]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.71      0.83      4010\n",
      "         1.0       0.04      0.80      0.07        55\n",
      "\n",
      "    accuracy                           0.71      4065\n",
      "   macro avg       0.52      0.75      0.45      4065\n",
      "weighted avg       0.98      0.71      0.82      4065\n",
      "\n",
      "{'base_estimator__C': 1000, 'base_estimator__max_iter': 2000, 'learning_rate': 0.1, 'n_estimators': 100}\n",
      "214.758150100708\n"
     ]
    }
   ],
   "source": [
    "## RusBoost with a support vector machine as base estimator \n",
    "start = time.time()\n",
    "clf_rus = RUSBoostClassifier(random_state = 78, base_estimator = LinearSVC(dual=False), algorithm='SAMME')\n",
    "\n",
    "param = {'n_estimators': [10, 25, 50, 100],\n",
    "         'learning_rate': [0.001, 0.01, 0.1, 0.5, 1],\n",
    "         'base_estimator__C' : [1000,2000,3000],\n",
    "         'base_estimator__max_iter': [2000]}\n",
    "\n",
    "search = GridSearchCV(clf_rus, param, cv=5)\n",
    "found = search.fit(X_train, y_train)  \n",
    "predicted = found.predict(X_val)\n",
    "print(confusion_matrix(y_val, predicted))\n",
    "print(classification_report(y_val, predicted))\n",
    "print(found.best_params_)\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Manual resampling of the data\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_res, y_res = rus.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2929 1081]\n",
      " [   4   51]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.73      0.84      4010\n",
      "         1.0       0.05      0.93      0.09        55\n",
      "\n",
      "    accuracy                           0.73      4065\n",
      "   macro avg       0.52      0.83      0.46      4065\n",
      "weighted avg       0.99      0.73      0.83      4065\n",
      "\n",
      "1341.4775426387787\n",
      "{'base_estimator__max_depth': 7, 'base_estimator__min_samples_leaf': 1, 'learning_rate': 1, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "## AdaBoost with a decision tree as base estimator\n",
    "start = time.time()\n",
    "clf_ada = AdaBoostClassifier(random_state = 145, base_estimator = DecisionTreeClassifier())\n",
    "\n",
    "param = {'n_estimators': [100, 150, 200],\n",
    "         'learning_rate': [0.001, 0.01, 0.1, 0.5, 1],\n",
    "         'base_estimator__min_samples_leaf': [1,2,3],\n",
    "         'base_estimator__max_depth': [5, 7, 9]}\n",
    "\n",
    "search = GridSearchCV(clf_ada, param, cv=5)\n",
    "found = search.fit(X_res, y_res)  \n",
    "predicted = found.predict(X_val)\n",
    "print(confusion_matrix(y_val, predicted))\n",
    "print(classification_report(y_val, predicted))\n",
    "stop = time.time()\n",
    "print(stop-start)\n",
    "print(found.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2856 1154]\n",
      " [   7   48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.71      0.83      4010\n",
      "         1.0       0.04      0.87      0.08        55\n",
      "\n",
      "    accuracy                           0.71      4065\n",
      "   macro avg       0.52      0.79      0.45      4065\n",
      "weighted avg       0.98      0.71      0.82      4065\n",
      "\n",
      "{'learning_rate': 0.001, 'n_estimators': 10}\n",
      "22.65563941001892\n"
     ]
    }
   ],
   "source": [
    "## AdaBoost with a random forest classifier as base estimator \n",
    "start  = time.time()\n",
    "clf_ada = AdaBoostClassifier(random_state = 676, base_estimator = RandomForestClassifier())\n",
    "\n",
    "param = {'n_estimators': [10,20,50,100],\n",
    "         'learning_rate': [0.001, 0.01, 0.1, 0.5, 1]}\n",
    "\n",
    "search = GridSearchCV(clf_ada, param, cv=5)\n",
    "found = search.fit(X_res, y_res)  \n",
    "predicted = found.predict(X_val)\n",
    "print(confusion_matrix(y_val, predicted))\n",
    "print(classification_report(y_val, predicted))\n",
    "print(found.best_params_)\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2677 1333]\n",
      " [  14   41]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.67      0.80      4010\n",
      "         1.0       0.03      0.75      0.06        55\n",
      "\n",
      "    accuracy                           0.67      4065\n",
      "   macro avg       0.51      0.71      0.43      4065\n",
      "weighted avg       0.98      0.67      0.79      4065\n",
      "\n",
      "{'learning_rate': 1, 'n_estimators': 25}\n",
      "30.74560284614563\n"
     ]
    }
   ],
   "source": [
    "## AdaBoost with a support vector machine as base estimator\n",
    "start = time.time()\n",
    "clf_ada = AdaBoostClassifier(random_state = 2, base_estimator = LinearSVC(), algorithm='SAMME')\n",
    "\n",
    "param = {'n_estimators': [10, 25, 50, 100, 200],\n",
    "         'learning_rate': [0.001, 0.01, 0.1, 0.5, 1]}\n",
    "\n",
    "search = GridSearchCV(clf_ada, param, cv=5)\n",
    "found = search.fit(X_res, y_res)  \n",
    "predicted = found.predict(X_val)\n",
    "print(confusion_matrix(y_val, predicted))\n",
    "print(classification_report(y_val, predicted))\n",
    "print(found.best_params_)\n",
    "stop = time.time()\n",
    "print(stop-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2604 1406]\n",
      " [   7   48]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.65      0.79      4010\n",
      "         1.0       0.03      0.87      0.06        55\n",
      "\n",
      "    accuracy                           0.65      4065\n",
      "   macro avg       0.52      0.76      0.43      4065\n",
      "weighted avg       0.98      0.65      0.78      4065\n",
      "\n",
      "{'learning_rate': 0.1, 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "## XGBoost with a support vector machine as base estimator \n",
    "clf_xgb = xgb.XGBClassifier(random_state=7)\n",
    "\n",
    "param = {'n_estimators': [10, 25, 50, 100, 200],\n",
    "         'learning_rate': [0.001, 0.01, 0.1, 0.5, 1]}\n",
    "\n",
    "search = GridSearchCV(clf_xgb, param, cv=5)\n",
    "found = search.fit(X_res, y_res) \n",
    "predicted = found.predict(X_val)\n",
    "print(confusion_matrix(y_val, predicted))\n",
    "print(classification_report(y_val, predicted))\n",
    "print(found.best_params_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
